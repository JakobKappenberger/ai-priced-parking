{
    "agent": "ppo",
    "batch_size": 2,
    "exploration": 0.1
}